# arch_team - Multi-Agent Requirements Engineering System

Ein modulares Multi-Agent-Framework fÃ¼r automatisiertes Requirements Mining, Analyse und Knowledge Graph Generierung.

## ğŸ“š Inhaltsverzeichnis

1. [Ãœberblick](#Ã¼berblick)
2. [Architektur-Varianten](#architektur-varianten)
3. [Agent-Typen](#agent-typen)
4. [Workflows](#workflows)
5. [API-Endpunkte](#api-endpunkte)
6. [Konfiguration](#konfiguration)
7. [Beispiele](#beispiele)

---

## Ãœberblick

Das arch_team System bietet **3 Hauptmodi** fÃ¼r Requirements Engineering:

| Modus | Beschreibung | Use Case |
|-------|--------------|----------|
| **AutoGen RAC** | Konversationsbasierte Multi-Agent-Analyse | Komplexe Requirements-Analyse mit Reflexion |
| **EventBus** | Event-driven Agent-Orchestrierung | Flexible Workflows mit Custom Logic |
| **Web Service** | REST API fÃ¼r Dokument-Mining | Batch-Processing von Dokumenten |

---

## Architektur-Varianten

### 1ï¸âƒ£ AutoGen RAC Team (Recommended)

**Datei:** `autogen_rac.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Task      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Planner    â”‚â”€â”€â”€â”€â–¶â”‚  Solver      â”‚
â”‚  Agent      â”‚     â”‚  Agent       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ (RAG Tool)
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Verifier    â”‚
                    â”‚  Agent       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    COVERAGE_OK? â”€â”
                           â”‚       â”‚
                           NO      YES
                           â”‚       â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â–¶ Output
```

**Features:**
- Round-robin Gruppenchat
- RAG-Tool fÃ¼r Kontext-Retrieval
- Termination: "COVERAGE_OK" oder Max 10 Messages
- Streaming Console Output

**Start:**
```bash
export ARCH_TASK="Extract functional requirements for authentication"
python -m arch_team.autogen_rac
```

---

### 2ï¸âƒ£ Custom EventBus System (Legacy)

**Datei:** `main.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Task Input     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  EventBus  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚        â”‚
    â–¼    â–¼    â–¼        â–¼
 â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”
 â”‚Plan â”‚â”‚Solveâ”‚â”‚Verifyâ”‚â”‚ DTO  â”‚
 â”‚Topicâ”‚â”‚Topicâ”‚â”‚Topic â”‚â”‚Topic â”‚
 â””â”€â”€â”¬â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜
    â”‚      â”‚      â”‚       â”‚
    â–¼      â–¼      â–¼       â–¼
  Planner Solver Verifier Frontend
  Agent   Agent  Agent    Handler
```

**Topics:**
- `TOPIC_PLAN` - Planning Phase
- `TOPIC_SOLVE` - Requirement Extraction
- `TOPIC_VERIFY` - Quality Check
- `TOPIC_DTO` - Frontend Output
- `TOPIC_TRACE` - Logging

**Start:**
```bash
python -m arch_team.main --mode chunk_miner --path "data/*.md"
```

---

### 3ï¸âƒ£ Web Service (Production)

**Datei:** `service.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React Client â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask Service   â”‚
â”‚  (Port 8000)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚          â”‚
    â–¼         â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk  â”‚â”‚   KG   â”‚â”‚  RAG   â”‚
â”‚ Miner  â”‚â”‚ Agent  â”‚â”‚ Search â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Endpoints:**
- `POST /api/mining/upload` - Document Mining
- `POST /api/kg/build` - Knowledge Graph
- `GET /api/kg/search/nodes` - Graph Query

**Start:**
```bash
python -m arch_team.service
# Frontend: http://localhost:8000
```

---

## Agent-Typen

### PlannerAgent

**Zweck:** Erstellt AusfÃ¼hrungsplan fÃ¼r Requirements-Analyse

**Input:**
```python
{"task": "Analyze security requirements"}
```

**Output:**
```
THOUGHTS: [Internal reasoning]
PLAN:
- Analyze authentication mechanisms
- Identify data protection requirements
- Check authorization patterns
- Verify compliance requirements
```

**Datei:** `agents/planner.py`

---

### SolverAgent

**Zweck:** Extrahiert und normalisiert Requirements

**Features:**
- RAG-Retrieval fÃ¼r Kontext
- Workbench-Tools (qdrant_search, python_exec)
- Chain-of-Thought Reasoning

**Input:**
```python
{
  "task": "Extract auth requirements",
  "plan": "Analyze authentication...",
  "critique": "[Optional feedback from Verifier]"
}
```

**Output:**
```
THOUGHTS: [Analysis process]
EVIDENCE: [Gathered context]
FINAL_ANSWER:
  REQ-001: System shall enforce password complexity
  REQ-002: System shall support multi-factor authentication
```

**Datei:** `agents/solver.py`

---

### VerifierAgent

**Zweck:** Validiert Requirements-VollstÃ¤ndigkeit

**Checks:**
- Anzahl Requirements (5-20 empfohlen)
- REQ-ID Format (REQ-###)
- Tag-Verteilung (functional, security, performance, ux, ops)

**Output:**
```
COVERAGE_OK  // oder
CRITIQUE: Missing performance requirements, only 3 REQs found
```

**Datei:** `agents/verifier.py`

---

### ChunkMinerAgent

**Zweck:** Mining von Requirements aus Dokumenten

**Flow:**
```
Document (PDF/DOCX/MD)
    â†“
extract_texts()          # Text-Extraktion
    â†“
chunk_payloads()         # Chunking mit Overlap
    â†“  [Chunk 1] [Chunk 2] [Chunk 3] ...
    â†“
mine_chunk() per Chunk   # LLM-Call pro Chunk
    â†“
aggregate DTOs           # Sammeln & Normalisieren
    â†“
Return: List[DTO]
```

**DTO Format:**
```json
{
  "req_id": "REQ-5a8f23-001",
  "title": "System shall provide user authentication",
  "tag": "security",
  "evidence_refs": [
    {
      "sourceFile": "requirements.docx",
      "sha1": "5a8f23abc",
      "chunkIndex": 1
    }
  ]
}
```

**Chunking-Parameter:**
- `max_tokens`: 800 (Standard) - Chunk-GrÃ¶ÃŸe
- `overlap_tokens`: 200 (Standard) - Ãœberlappung
- `neighbor_refs`: true - Inkludiert Â±1 Chunks als Evidence

**Datei:** `agents/chunk_miner.py`

---

### KGAbstractionAgent

**Zweck:** Baut Knowledge Graph aus Requirements

**Node-Typen:**
- **Requirement**: Eigentliches Requirement
- **Tag**: Kategorie (functional, security, etc.)
- **Actor**: Akteur (User, System, etc.)
- **Entity**: EntitÃ¤t (Password, Profile, etc.)
- **Action**: Verb (authenticate, validate, etc.)

**Edge-Typen:**
- **HAS_TAG**: Requirement â†’ Tag
- **HAS_ACTOR**: Requirement â†’ Actor
- **HAS_ACTION**: Requirement â†’ Action
- **ON_ENTITY**: Action â†’ Entity

**Beispiel:**
```
Requirement: "User can reset password"

Nodes:
  REQ-001 (Requirement)
  User (Actor)
  reset (Action)
  Password (Entity)
  functional (Tag)

Edges:
  REQ-001 --HAS_ACTOR--> User
  REQ-001 --HAS_ACTION--> reset
  reset --ON_ENTITY--> Password
  REQ-001 --HAS_TAG--> functional
```

**Extraction-Modi:**
1. **Heuristic**: Regex-basierte Keyword-Extraktion (schnell)
2. **LLM**: Optional fÃ¼r komplexe FÃ¤lle (prÃ¤zise)
3. **Hybrid**: Heuristik + LLM Fallback (empfohlen)

**Datei:** `agents/kg_agent.py`

---

## Workflows

### Workflow 1: Document Mining (Web Service)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User uploads document.docx via React Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. POST /api/mining/upload                          â”‚
â”‚    FormData: {files, model, neighbor_refs,          â”‚
â”‚               chunk_size, chunk_overlap}            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ChunkMinerAgent.mine_files_or_texts_collect()   â”‚
â”‚    â”œâ”€ extract_texts() â†’ "Full document text..."    â”‚
â”‚    â”œâ”€ chunk_payloads(max=800, overlap=200)         â”‚
â”‚    â”‚   â†’ [Chunk1, Chunk2, Chunk3, ...]             â”‚
â”‚    â”œâ”€ For each chunk:                               â”‚
â”‚    â”‚   â””â”€ LLM Call â†’ JSON extraction                â”‚
â”‚    â””â”€ Aggregate â†’ List[DTO]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Return {success: true, count: 42, items: [...]} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Frontend displays Requirements List              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. POST /api/kg/build                               â”‚
â”‚    JSON: {items: [...], options: {...}}            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. KGAbstractionAgent.run()                         â”‚
â”‚    â”œâ”€ For each DTO:                                 â”‚
â”‚    â”‚   â”œâ”€ Heuristic extraction â†’ Nodes/Edges       â”‚
â”‚    â”‚   â””â”€ Optional LLM expansion                    â”‚
â”‚    â”œâ”€ Deduplication                                 â”‚
â”‚    â””â”€ Persist to Qdrant (kg_nodes_v1, kg_edges_v1) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Return {nodes: [...], edges: [...], stats}      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Frontend renders Interactive Knowledge Graph     â”‚
â”‚    (Cytoscape.js visualization)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Workflow 2: RAC Analysis (AutoGen)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User starts: python -m arch_team.autogen_rac    â”‚
â”‚    ARCH_TASK="Analyze payment system requirements" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RoundRobinGroupChat initializes                  â”‚
â”‚    Agents: [Planner, Solver, Verifier]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Planner turn:                                    â”‚
â”‚    Output: PLAN with 3-5 analysis steps             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Solver turn:                                     â”‚
â”‚    â”œâ”€ Reads PLAN from Planner                       â”‚
â”‚    â”œâ”€ Optional: Calls RAG tool (search_requirements)â”‚
â”‚    â”‚   â†’ Retrieves context from Qdrant              â”‚
â”‚    â”œâ”€ LLM reasoning                                 â”‚
â”‚    â””â”€ Output: FINAL_ANSWER with REQ-001, REQ-002... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Verifier turn:                                   â”‚
â”‚    â”œâ”€ Checks requirement count                      â”‚
â”‚    â”œâ”€ Validates REQ-ID format                       â”‚
â”‚    â”œâ”€ Checks tag distribution                       â”‚
â”‚    â””â”€ Output: "COVERAGE_OK" or CRITIQUE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
                â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                â”‚           â”‚
         COVERAGE_OK    CRITIQUE
                â”‚           â”‚
                â”‚           â–¼
                â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    â”‚ Back to Solver  â”‚
                â”‚    â”‚ with feedback   â”‚
                â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚           â”‚
                â”‚           â–¼
                â”‚    [Loop max 10x]
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Termination: Output final requirements           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## API-Endpunkte

### POST /api/mining/upload

**Dokument-Mining**

**Request:**
```bash
curl -X POST http://localhost:8000/api/mining/upload \
  -F "files=@document.docx" \
  -F "model=gpt-4o-mini" \
  -F "neighbor_refs=1" \
  -F "chunk_size=1200" \
  -F "chunk_overlap=300"
```

**Response:**
```json
{
  "success": true,
  "count": 15,
  "items": [
    {
      "req_id": "REQ-a3b2c1-001",
      "title": "System shall authenticate users via OAuth2",
      "tag": "security",
      "evidence_refs": [
        {"sourceFile": "document.docx", "sha1": "a3b2c1", "chunkIndex": 2}
      ]
    }
  ]
}
```

**Parameter:**
- `files`: Multipart files (PDF, DOCX, MD, TXT)
- `model`: Optional (default: gpt-4o-mini)
- `neighbor_refs`: "1"|"true" fÃ¼r Â±1 Chunk Context
- `chunk_size`: Tokens pro Chunk (default: 800)
- `chunk_overlap`: Overlap-Tokens (default: 200)

---

### POST /api/kg/build

**Knowledge Graph Generierung**

**Request:**
```bash
curl -X POST http://localhost:8000/api/kg/build \
  -H "Content-Type: application/json" \
  -d '{
    "items": [...],
    "options": {
      "persist": "qdrant",
      "use_llm": false,
      "llm_fallback": true,
      "persist_async": true
    }
  }'
```

**Response:**
```json
{
  "success": true,
  "nodes": [...],
  "edges": [...],
  "stats": {
    "nodes": 87,
    "edges": 143,
    "deduped": 12,
    "persisted_nodes": 87,
    "persisted_edges": 143
  }
}
```

**Options:**
- `persist`: "qdrant" | "none"
- `use_llm`: true fÃ¼r LLM-basierte Extraktion
- `llm_fallback`: true â†’ LLM wenn Heuristik wenig findet
- `persist_async`: true fÃ¼r Background-Persistence

---

### GET /api/kg/search/nodes

**Semantic Node Search**

```bash
curl "http://localhost:8000/api/kg/search/nodes?query=authentication&top_k=5"
```

**Response:**
```json
{
  "success": true,
  "results": [
    {
      "id": "REQ-001",
      "type": "Requirement",
      "name": "User authentication",
      "score": 0.89
    }
  ]
}
```

---

### GET /api/kg/neighbors

**Graph Traversal (1-hop)**

```bash
curl "http://localhost:8000/api/kg/neighbors?node_id=REQ-001&dir=both&rel=HAS_ACTION&limit=50"
```

**Parameter:**
- `node_id`: Start-Node
- `dir`: "in" | "out" | "both"
- `rel`: Filter by relation type (comma-separated)
- `limit`: Max results (default: 200)

---

## Konfiguration

### Environment Variables (.env)

```bash
# OpenAI
OPENAI_API_KEY=sk-...
MODEL_NAME=gpt-4o-mini
ARCH_TEMPERATURE=0.2

# AutoGen RAC
ARCH_TASK="Analyze requirements..."
RAC_RAG_ENABLED=1
RAC_MAX_MESSAGES=10

# EventBus Mode
ARCH_REFLECTION_ROUNDS=1
ARCH_MODEL_CONTEXT_MAX=12

# ChunkMiner
CHUNK_MINER_NEIGHBORS=1

# Qdrant
QDRANT_URL=http://localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=requirements_v2
# Collections auto-created: kg_nodes_v1, kg_edges_v1, arch_trace

# Service
APP_PORT=8000
```

---

## Beispiele

### Beispiel 1: CLI Mining

```bash
# Mit Neighbor Evidence
python -m arch_team.main \
  --mode chunk_miner \
  --path "specs/*.md" \
  --neighbor-evidence \
  --model gpt-4o-mini
```

### Beispiel 2: Python API

```python
from arch_team.agents.chunk_miner import ChunkMinerAgent

agent = ChunkMinerAgent(source="api", default_model="gpt-4o-mini")

# Mining from files
with open("requirements.md", "rb") as f:
    items = agent.mine_files_or_texts_collect(
        files_or_texts=[f.read()],
        neighbor_refs=True,
        chunk_options={"max_tokens": 1200, "overlap_tokens": 300}
    )

print(f"Extracted {len(items)} requirements")
```

### Beispiel 3: Knowledge Graph

```python
from arch_team.agents.kg_agent import KGAbstractionAgent

kg_agent = KGAbstractionAgent()

result = kg_agent.run(
    items=requirements_dtos,
    persist="qdrant",
    use_llm=False,
    llm_fallback=True
)

print(f"Created {result['stats']['nodes']} nodes, {result['stats']['edges']} edges")
```

---

## Performance-Tipps

### Chunking-Optimierung

| Dokument-Typ | chunk_size | overlap | neighbor_refs |
|--------------|------------|---------|---------------|
| Kurze Specs (< 10 Seiten) | 600 | 150 | false |
| Mittlere Docs (10-50 Seiten) | 800 | 200 | true |
| Lange Standards (> 50 Seiten) | 1200 | 300 | true |
| Sehr dichte Texte | 1600 | 400 | true |

### Model-Wahl

| Modell | Geschwindigkeit | QualitÃ¤t | Kosten | Use Case |
|--------|-----------------|----------|--------|----------|
| gpt-4o-mini | âš¡âš¡âš¡ | âœ“âœ“ | $ | Standard-Mining |
| gpt-4o | âš¡âš¡ | âœ“âœ“âœ“ | $$$ | Komplexe Dokumente |
| gpt-4 | âš¡ | âœ“âœ“âœ“ | $$$$ | HÃ¶chste QualitÃ¤t |

### Batch-Processing

FÃ¼r groÃŸe Mengen:
```bash
# Parallel processing mit xargs
find specs/ -name "*.md" | xargs -P 4 -I {} \
  python -m arch_team.main --mode chunk_miner --path {}
```

---

## Troubleshooting

### Problem: Zu wenige Requirements extrahiert

**LÃ¶sung:**
1. âœ… ErhÃ¶he `chunk_size` (z.B. 1200)
2. âœ… Aktiviere `neighbor_refs=true`
3. âœ… ErhÃ¶he `chunk_overlap` (z.B. 300)
4. âœ… PrÃ¼fe Dokument-Format (DOCX-Extraktion OK?)

### Problem: Knowledge Graph leer

**LÃ¶sung:**
1. âœ… Aktiviere `llm_fallback=true`
2. âœ… PrÃ¼fe DTO-Format (req_id, title, tag vorhanden?)
3. âœ… Logs prÃ¼fen: `arch_team/runtime/logging.py`

### Problem: Langsame Performance

**LÃ¶sung:**
1. âœ… Reduziere `chunk_size` (weniger Chunks)
2. âœ… Deaktiviere `neighbor_refs` (schneller)
3. âœ… Nutze `gpt-4o-mini` statt `gpt-4o`
4. âœ… Aktiviere `persist_async=true` fÃ¼r KG

---

## WeiterfÃ¼hrende Dokumentation

- **Agent-Details:** Siehe `agents/` README
- **Runtime:** Siehe `runtime/` README
- **Tools:** Siehe `autogen_tools/` README
- **Memory:** Siehe `memory/` README

---

## Support

Bei Fragen siehe:
- GitHub Issues: [Link]
- CLAUDE.md (Root-Verzeichnis)
- Inline-Docstrings in Agent-Klassen
