# Requirements Validation - Society of Mind Design

**Status**: Design Phase
**Pattern**: AutoGen Society of Mind + Tool Calling
**Reference Implementation**: `arch_team/dev_folder_/agent.py` (GitHub MCP Agent)

---

## ğŸ¯ **Zielsetzung**

Automatisierte Requirements-QualitÃ¤tssicherung mit:
- âœ… Multi-Kriterien Evaluation (Clarity, Testability, Measurability)
- âœ… Automatische VerbesserungsvorschlÃ¤ge (Atomic Suggestions)
- âœ… LLM-basiertes Rewriting (User Story Format, Acceptance Criteria)
- âœ… Duplikats-Erkennung (Semantic Search via Embeddings)
- âœ… User-Interaktion fÃ¼r fehlende Informationen

---

## ğŸ—ï¸ **Architektur: Society of Mind Pattern**

### **Ãœbersicht**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SocietyOfMindAgent ("requirements_society_of_mind")             â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RoundRobinGroupChat (Inner Team, max_turns=20)           â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚  â”‚ 1ï¸âƒ£ RequirementsOperator                       â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Role: Validate & improve requirements       â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Tools:                                       â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   - evaluate_requirement()                     â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   - rewrite_requirement()                      â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   - suggest_improvements()                     â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   - detect_duplicates()                        â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Signal: "READY_FOR_VALIDATION"              â”‚        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â”‚                        â†•                                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚  â”‚ 2ï¸âƒ£ UserClarificationAgent                     â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Role: Get missing info from user            â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Tool: ask_user(question, suggestions)        â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Trigger: "NEED_USER_CLARIFICATION: xyz"     â”‚        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â”‚                        â†•                                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚  â”‚ 3ï¸âƒ£ QAValidator                                 â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Role: Verify completeness & quality          â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Tools: None (validation only)                â”‚        â”‚  â”‚
â”‚  â”‚  â”‚   Termination: "APPROVE"                       â”‚        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚  Termination: TextMentionTermination("APPROVE")           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  Model: OpenAIChatCompletionClient (via OpenAIAdapter)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ **Tool-Spezifikation**

### **1. evaluate_requirement**

**API Endpoint**: `POST /api/v2/evaluate/single`
**Service**: `backend_app_v2/services/evaluation_service.py`

**Input**:
```python
{
    "text": "Die Plattform muss schnell sein",
    "criteria_keys": ["clarity", "testability", "measurability"]
}
```

**Output**:
```python
{
    "score": 0.42,
    "verdict": "fail",
    "evaluation": [
        {
            "criterion": "clarity",
            "score": 0.3,
            "passed": false,
            "feedback": "Schwammige Formulierung: 'schnell' ist nicht messbar"
        },
        {
            "criterion": "testability",
            "score": 0.5,
            "passed": false,
            "feedback": "Keine Akzeptanzkriterien definiert"
        },
        {
            "criterion": "measurability",
            "score": 0.45,
            "passed": false,
            "feedback": "Fehlende Metriken (z.B. Latenz <2s)"
        }
    ]
}
```

**Tool Signature**:
```python
async def evaluate_requirement(
    requirement_text: Annotated[str, "The requirement to evaluate"],
    criteria_keys: Annotated[List[str], "Quality criteria"] = None
) -> Dict[str, Any]
```

---

### **2. rewrite_requirement**

**API Endpoint**: `POST /api/v1/validate/batch`
**Service**: `backend_app_v2/routers/validate_router.py`

**Input**:
```python
{
    "items": ["Die Plattform muss schnell sein"]
}
```

**Output**:
```python
[{
    "id": 1,
    "originalText": "Die Plattform muss schnell sein",
    "correctedText": "Als Nutzer mÃ¶chte ich Seitenladezeiten <2s (P95), damit ich effizient arbeiten kann",
    "status": "accepted",
    "score": 0.88,
    "verdict": "pass",
    "evaluation": [...]
}]
```

**Tool Signature**:
```python
async def rewrite_requirement(
    requirement_text: Annotated[str, "The requirement to improve"]
) -> Dict[str, Any]
```

---

### **3. suggest_improvements**

**API Endpoint**: `POST /api/v1/validate/suggest`
**Service**: `backend_app/llm.py:llm_suggest`

**Input**:
```python
{
    "items": ["Die Plattform muss schnell sein"]
}
```

**Output**:
```python
{
    "items": {
        "REQ_1": {
            "suggestions": [
                {
                    "type": "add_actor",
                    "suggestion": "FÃ¼ge User Story Format hinzu: 'Als [Rolle] mÃ¶chte ich...'",
                    "priority": "high"
                },
                {
                    "type": "add_metric",
                    "suggestion": "Spezifiziere Performance-Metrik: 'Latenz <2000ms (P95)'",
                    "priority": "high"
                },
                {
                    "type": "add_criteria",
                    "suggestion": "ErgÃ¤nze Akzeptanzkriterien: 'Given...When...Then...'",
                    "priority": "medium"
                }
            ]
        }
    }
}
```

**Tool Signature**:
```python
async def suggest_improvements(
    requirement_text: Annotated[str, "The requirement to analyze"]
) -> List[Dict[str, Any]]
```

---

### **4. detect_duplicates**

**API Endpoint**: `POST /api/kg/search/nodes` (semantic search in Qdrant)
**Service**: `arch_team/memory/qdrant_kg.py`

**Input**:
```python
{
    "requirements": [
        "Video-Wasserzeichen fÃ¼r Urheberrecht",
        "Wasserzeichen in Videos einfÃ¼gen"
    ]
}
```

**Output**:
```python
[
    {
        "req1_idx": 0,
        "req2_idx": 1,
        "similarity": 0.94,
        "reason": "Beide beschreiben Video-Wasserzeichen fÃ¼r Urheberrecht"
    }
]
```

**Tool Signature**:
```python
async def detect_duplicates(
    requirements: Annotated[List[str], "Requirements to check"]
) -> List[Dict[str, Any]]
```

**Implementation Status**: TODO (Qdrant semantic search)

---

## ğŸ“œ **Agent Prompts**

### **RequirementsOperator Prompt**

**Datei**: `arch_team/agents/prompts/requirements_operator_prompt.py`

**Inhalt**:
```
ROLE: Requirements Operator
GOAL: Validate and improve software requirements

TOOLS:
- evaluate_requirement: Assess quality (score 0-1)
- rewrite_requirement: Improve structure
- suggest_improvements: Generate atomic fixes
- detect_duplicates: Find semantic overlaps

WORKFLOW:
1. Evaluate quality with evaluate_requirement()
2. If score < 0.7:
   a. Call suggest_improvements() for specific fixes
   b. Call rewrite_requirement() for improved version
3. For multiple requirements: Call detect_duplicates()
4. Signal completion: "READY_FOR_VALIDATION"

CLARIFICATION:
If info missing (e.g., criteria selection):
"NEED_USER_CLARIFICATION: <what is missing>"

OUTPUT:
- Quality scores
- Improvement suggestions
- Rewritten requirements
- Duplicate warnings
- "READY_FOR_VALIDATION"
```

---

### **UserClarificationAgent Prompt**

**Datei**: `arch_team/agents/prompts/user_clarification_prompt.py`

**Inhalt**:
```
ROLE: User Clarification Agent

TOOL: ask_user(question, suggested_answers=[])

WORKFLOW:
1. Detect: "NEED_USER_CLARIFICATION: xyz"
2. Call: ask_user("German question", ["option1", "option2"])
3. Wait for user response (via conversation)
4. Relay: "The user provided: <answer>. RequirementsOperator, continue..."

RULES:
- Questions in GERMAN
- ONE question at a time
- NEVER assume answers
```

---

### **QAValidator Prompt**

**Datei**: `arch_team/agents/prompts/qa_validator_prompt.py`

**Inhalt**:
```
ROLE: QA Validator

CHECKLIST:
- âœ“ evaluate_requirement called?
- âœ“ Quality scores documented?
- âœ“ If score < 0.7: Improvements applied?
- âœ“ Duplicates checked?
- âœ“ Output clear and actionable?

RESPONSE:
âœ“ "APPROVE: <summary>"
âœ— "NOT APPROVED: <issues>"
```

---

## ğŸ”„ **Beispiel-Ablauf**

### **Scenario 1: Low-Quality Requirement**

**Input**:
```
Requirement: "Die App muss schnell sein"
```

**Execution Flow**:

```
1. [RequirementsOperator]
   â†’ Tool: evaluate_requirement(text="Die App muss schnell sein")
   â†’ Result: {"score": 0.35, "verdict": "fail"}

   â†’ Tool: suggest_improvements(text="...")
   â†’ Result: [
       {"type": "add_actor", "suggestion": "Als Nutzer mÃ¶chte ich..."},
       {"type": "add_metric", "suggestion": "Latenz <2s (P95)"}
     ]

   â†’ Tool: rewrite_requirement(text="...")
   â†’ Result: {
       "correctedText": "Als Nutzer mÃ¶chte ich Seitenladezeiten <2s (P95), damit ich effizient arbeite"
     }

   â†’ "READY_FOR_VALIDATION"

2. [QAValidator]
   â†’ Checks:
     - evaluate_requirement âœ“
     - score documented (0.35) âœ“
     - improvements suggested âœ“
     - rewrite applied âœ“

   â†’ "APPROVE: Requirement validated (score: 0.35â†’0.88 after rewrite)"

3. âœ… TERMINATION
```

---

### **Scenario 2: Missing Information**

**Input**:
```
Requirement: "System soll skalierbar sein"
Context: User didn't specify criteria
```

**Execution Flow**:

```
1. [RequirementsOperator]
   â†’ "NEED_USER_CLARIFICATION: Which criteria should be checked?"

2. [UserClarificationAgent]
   â†’ Tool: ask_user(
       question="Welche QualitÃ¤tskriterien sollen geprÃ¼ft werden?",
       suggested_answers=["clarity", "testability", "all"]
     )
   â†’ (Waits for user via GUI/file polling)

3. [User via GUI]
   â†’ Answer: "all"

4. [UserClarificationAgent]
   â†’ "The user provided: all. RequirementsOperator, validate against all criteria."

5. [RequirementsOperator]
   â†’ Tool: evaluate_requirement(text="...", criteria_keys=["clarity", "testability", "measurability"])
   â†’ Continue workflow...
```

---

## ğŸ“‚ **Dateistruktur**

```
arch_team/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ validation_tools.py          # FunctionTool definitions
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requirements_operator_prompt.py
â”‚   â”‚   â”œâ”€â”€ qa_validator_prompt.py
â”‚   â”‚   â””â”€â”€ user_clarification_prompt.py
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements_agent.py        # Main SocietyOfMindAgent wrapper
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ REQUIREMENTS_VALIDATION_DESIGN.md  # This file
â””â”€â”€ ...
```

---

## ğŸ”Œ **Integration Points**

### **Backend APIs (bereits vorhanden)**

| API Endpoint | Service | Status |
|-------------|---------|--------|
| `/api/v2/evaluate/single` | EvaluationService | âœ… Implemented |
| `/api/v1/validate/batch` | validate_router | âœ… Implemented |
| `/api/v1/validate/suggest` | validate_router | âœ… Implemented |
| `/api/kg/search/nodes` | QdrantKGClient | âœ… Implemented |

### **AutoGen Dependencies**

```python
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.agents import AssistantAgent, SocietyOfMindAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination
from autogen_core.tools import FunctionTool
```

### **arch_team Dependencies**

```python
from arch_team.model.openai_adapter import OpenAIAdapter
from arch_team.memory.qdrant_kg import QdrantKGClient
```

---

## ğŸš€ **NÃ¤chste Schritte (Implementation)**

### **Phase 1: Tools** (2-3 Stunden)
- [x] Design: Tool-Spezifikation
- [ ] Code: `arch_team/tools/validation_tools.py`
  - [ ] evaluate_requirement (HTTP â†’ backend_app_v2)
  - [ ] rewrite_requirement (HTTP â†’ backend_app_v2)
  - [ ] suggest_improvements (HTTP â†’ backend_app_v2)
  - [ ] detect_duplicates (Qdrant semantic search)
  - [ ] VALIDATION_TOOLS export

### **Phase 2: Prompts** (1-2 Stunden)
- [x] Design: Prompt-Spezifikation
- [ ] Code: `arch_team/agents/prompts/*.py`
  - [ ] requirements_operator_prompt.py
  - [ ] qa_validator_prompt.py
  - [ ] user_clarification_prompt.py

### **Phase 3: Agent** (3-4 Stunden)
- [x] Design: Society of Mind Architecture
- [ ] Code: `arch_team/agents/requirements_agent.py`
  - [ ] RequirementsValidationAgent class
  - [ ] initialize() method
  - [ ] validate_requirements() method
  - [ ] ask_user tool (file-based polling)
  - [ ] SocietyOfMindAgent setup
  - [ ] RoundRobinGroupChat mit Termination

### **Phase 4: Testing** (2-3 Stunden)
- [ ] Unit-Tests: Tool HTTP calls
- [ ] Integration-Test: End-to-End validation flow
- [ ] User-Interaction-Test: ask_user polling
- [ ] Performance-Test: Batch validation (10+ requirements)

### **Phase 5: Frontend Integration** (Optional)
- [ ] React Component: RequirementValidator.jsx
- [ ] Live updates via EventBus
- [ ] Quality scorecard visualization

---

## ğŸ“Š **Erfolgs-Kriterien**

- âœ… Requirements mit score < 0.7 werden automatisch verbessert
- âœ… User Story Format wird korrekt angewendet
- âœ… Acceptance Criteria werden vorgeschlagen
- âœ… Duplikate werden erkannt (Similarity > 0.9)
- âœ… User-Clarification funktioniert via GUI
- âœ… QAValidator prÃ¼ft alle Schritte korrekt
- âœ… End-to-End Latenz < 30s fÃ¼r 5 Requirements

---

## ğŸ”— **Referenzen**

- **AutoGen Society of Mind**: https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/society-of-mind.html
- **Referenz-Implementation**: `arch_team/dev_folder_/agent.py` (GitHub MCP Agent)
- **Backend Evaluation API**: `backend_app_v2/services/evaluation_service.py`
- **Requirements Engineering Best Practices**: IEEE 29148, IREB CPRE
