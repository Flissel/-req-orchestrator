# Kopiere diese Datei nach ".env" und passe die Werte an.
# Beispiel: cp .env.example .env

# ========= Runtime =========
API_HOST=0.0.0.0
API_PORT=8000

# ========= Datenbank =========
SQLITE_PATH=/app/data/app.db
PURGE_RETENTION_H=24

# ========= LLM =========
# Wenn OPENAI_API_KEY leer ist oder MOCK_MODE=true, werden Heuristiken genutzt.
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
MOCK_MODE=false
LLM_TEMPERATURE=0.0
LLM_TOP_P=1.0
LLM_MAX_TOKENS=0

# ========= Evaluation / Scoring =========
VERDICT_THRESHOLD=0.8
SUGGEST_MAX=10

# ========= Kriterien / Prompts =========
CRITERIA_CONFIG_PATH=./config/criteria.json
EVAL_SYSTEM_PROMPT_PATH=./config/prompts/evaluate.system.txt
SUGGEST_SYSTEM_PROMPT_PATH=./config/prompts/suggest.system.txt
REWRITE_SYSTEM_PROMPT_PATH=./config/prompts/rewrite.system.txt

# ========= Qdrant / Vector =========
# QDRANT_PORT (HTTP) primär 6333; Fallback HTTP-Host-Port 6401 (siehe docker-compose.qdrant.yml)
QDRANT_URL=http://host.docker.internal
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_COLLECTION=requirements_v1

# ========= Embeddings =========
EMBEDDINGS_PROVIDER=openai
EMBEDDINGS_MODEL=text-embedding-3-small
# DIM kann via Autodetect bestimmt werden; ansonsten Default setzen
EMBEDDINGS_DIM=1536

# ========= Batch / Parallelität =========
BATCH_SIZE=10
MAX_PARALLEL=5

# ========= IO Pfade =========
REQUIREMENTS_MD_PATH=./docs/requirements.md
OUTPUT_MD_PATH=./data/requirements.out.md

# ========= Versionierung / Canary =========
# FEATURE_FLAG_USE_V2: steuert Routing (v1 Legacy vs v2 FastAPI). CANARY_PERCENT in %.
FEATURE_FLAG_USE_V2=true
CANARY_PERCENT=100

# Legacy/V2 Basis-URLs (für Proxy/Frontend/Agenten)
LEGACY_BASE_URL=http://localhost:5000
V2_BASE_URL=http://localhost:8087

# ========= Logging =========
LOG_LEVEL=INFO