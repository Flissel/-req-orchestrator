# Anforderungen an die aktuelle Backend-Software

| id  | requirementText                                                                                                                                                                                                                                          | context                                                  |
| --- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------- |
| R1  | Das Backend stellt einen Health-Endpoint unter GET /health bereit, der innerhalb von 200 ms mit {"status":"ok"} antwortet.                                                                                                                               | {"language":"de","area":"ops","priority":"high"}         |
| R2  | Der Endpoint GET /api/v1/criteria liefert alle aktiven Evaluationskriterien mit key, name, weight, active als JSON.                                                                                                                                      | {"language":"de","area":"api","priority":"high"}         |
| R3  | Der Endpoint POST /api/v1/evaluations akzeptiert requirementText (String), optional context (Objekt) und optional criteriaKeys (Array), validiert die Eingabe und antwortet mit evaluationId, verdict, score, latencyMs, model, details und suggestions. | {"language":"de","area":"api","priority":"high"}         |
| R4  | Der Klartext des requirementText wird nicht persistent gespeichert; stattdessen wird ausschließlich eine SHA-256 Prüfsumme in der Tabelle evaluation.requirment_checksum abgelegt.                                                                     | {"language":"de","area":"security","priority":"high"}    |
| R5  | Das Datenbankschema umfasst die Tabellen criterion, evaluation, evaluation_detail, suggestion und rewritten_requirement mit Foreign Keys und Indizes auf created_at und requirement_checksum.                                                            | {"language":"de","area":"db","priority":"high"}          |
| R6  | Die Batch-Routen lesen die Markdown-Datei aus REQUIREMENTS_MD_PATH (Standard ./docs/requirements.md) und verarbeiten jede Tabellenzeile separat.                                                                                                         | {"language":"de","area":"batch","priority":"high"}       |
| R7  | POST /api/v1/batch/evaluate berechnet für jede Zeile evaluationScore und verdict, persistiert Evaluationsergebnisse und liefert zusätzlich mergedMarkdown als Text.                                                                                    | {"language":"de","area":"batch","priority":"high"}       |
| R8  | POST /api/v1/batch/suggest erzeugt bis zu drei prägnante Verbesserungsvorschläge pro Anforderung, schreibt diese sequenziell in die DB und liefert mergedMarkdown.                                                                                     | {"language":"de","area":"batch","priority":"high"}       |
| R9  | POST /api/v1/batch/rewrite erzeugt pro Anforderung einen präzise umformulierten redefinedRequirement, speichert ihn sequenziell und liefert mergedMarkdown.                                                                                             | {"language":"de","area":"batch","priority":"high"}       |
| R10 | Parallele LLM-Aufrufe in Batch-Routen sind über MAX_PARALLEL (Standard 3) und BATCH_SIZE (Standard 10) begrenzt; alle DB-Schreibvorgänge erfolgen sequenziell, um SQLite Fehler zu vermeiden.                                                          | {"language":"de","area":"performance","priority":"high"} |
| R11 | Die LLM-Integration nutzt das Modell aus OPENAI_MODEL (Standard gpt-4o-mini); bei MOCK_MODE=true wird deterministische Heuristik ohne externe Aufrufe verwendet.                                                                                         | {"language":"de","area":"llm","priority":"high"}         |
| R12 | Konfiguration erfolgt über Umgebungsvariablen (.env) gemäß backend_app/settings.py; fehlende Variablen besitzen sinnvolle Defaults.                                                                                                                   | {"language":"de","area":"config","priority":"high"}      |
| R13 | Docker Compose mountet ./docs read-only nach /app/docs und ./data nach /data; die SQLite-Datei wird unter /data/app.db betrieben.                                                                                                                        | {"language":"de","area":"ops","priority":"high"}         |
| R14 | CORS ist für /api/* aktiviert, um Frontend-Entwicklung zu erleichtern, ohne Credentials zu unterstützen.                                                                                                                                               | {"language":"de","area":"api","priority":"medium"}       |
| R15 | Es gelten einheitliche Fehlercodes: 400 invalid_request, 429 rate_limited, 502 llm_upstream_error, 500 internal_error.                                                                                                                                   | {"language":"de","area":"api","priority":"high"}         |
| R16 | p95 Latenz beträgt höchstens 2000 ms bei 30 Requests pro Minute in der Referenzumgebung (lokal/Compose).                                                                                                                                               | {"language":"de","area":"performance","priority":"high"} |
| R17 | Es werden keine sensitiven Inhalte in Logs geschrieben; Logging umfasst höchstens IDs, Latenzen und Modellnamen.                                                                                                                                        | {"language":"de","area":"security","priority":"high"}    |
| R18 | Alte Evaluationen werden gemäß PURGE_RETENTION_H (Standard 24 Stunden) beim Start automatisch bereinigt.                                                                                                                                               | {"language":"de","area":"ops","priority":"medium"}       |
| R19 | Der Markdown-Parser erwartet die Spalten id, requirementText, context; context bevorzugt als JSON, sonst wird der Inhalt als note im Kontext abgelegt.                                                                                                   | {"language":"de","area":"batch","priority":"medium"}     |
| R20 | Das Backend wird als WSGI-Anwendung über Gunicorn (wsgi:app) gestartet; die Container-Commandline definiert standardmäßig mindestens zwei Worker-Prozesse.                                                                                            | {"language":"de","area":"ops","priority":"medium"}       |
